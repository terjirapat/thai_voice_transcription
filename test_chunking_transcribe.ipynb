{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f4b5df",
   "metadata": {},
   "source": [
    "‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏ï‡∏±‡∏î‡∏ï‡∏≠‡∏ô‡∏û‡∏π‡∏î‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î‡∏ï‡∏≠‡∏ô‡∏Å‡∏µ‡πà‡∏ß‡∏¥ split chunk\n",
    "\n",
    "overlap text ‡∏ó‡∏µ‡πà merge ‡∏Å‡∏±‡∏ô‡∏à‡∏∞‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏á\n",
    "\n",
    "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏à‡∏π‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ\n",
    "\n",
    "‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏ß‡πÜ‡πÅ‡∏•‡πâ‡∏ß‡∏ã‡∏≠‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô overlap ‡∏Å‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡∏™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf1df3",
   "metadata": {},
   "source": [
    "‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô temp file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c062d7",
   "metadata": {},
   "source": [
    "lib ‡∏™‡∏£‡πâ‡∏≤‡∏á temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf05a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a2bc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.typhoon.inference import TyphoonASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4900f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå™Ô∏è Loading Typhoon ASR model on CPU...\n",
      "[NeMo I 2025-11-19 13:17:30 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 2048 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-11-19 13:17:31 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/stt_th_conformer_transducer_large/prepare_data/typhoon_cleanser/20250814/Split_gg/train_data_typhoon_asr_realtime.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 30.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-11-19 13:17:31 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/workspace/warit/nemo-asr/data/scbx_testset_manifest.jsonl\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 30.0\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2025-11-19 13:17:31 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-11-19 13:17:31 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-11-19 13:17:32 nemo_logging:393] d:\\Git\\thai_voice_transcription\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-11-19 13:17:32 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-11-19 13:17:32 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-11-19 13:17:32 nemo_logging:393] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-11-19 13:17:33 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-11-19 13:17:33 nemo_logging:393] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-11-19 13:17:33 nemo_logging:381] Model EncDecRNNTBPEModel was successfully restored from C:\\Users\\TDGE0049\\.cache\\huggingface\\hub\\models--scb10x--typhoon-asr-realtime\\snapshots\\a14b79d50c788dbdfe559c8a28a9b90153cf3865\\typhoon-asr-realtime.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = TyphoonASR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d68b15e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampled: 48000 Hz ‚Üí 16000 Hz\n",
      "‚úÖ Saved: processed_audio.wav (2.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡∏•‡∏∞ chunk\n",
    "chunk_files = sorted(glob.glob(\"audio/chunks_fah/*.wav\"))\n",
    "texts = []\n",
    "\n",
    "for chunk_file in chunk_files:\n",
    "    processed = model.preprocess(chunk_file)\n",
    "    result = model.transcribe(processed)\n",
    "    text = result['text'][0] if result['text'] else ''\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c47219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_overlapped_text(texts):\n",
    "    if not texts:\n",
    "        return \"\"\n",
    "    \n",
    "    merged = texts[0]\n",
    "    \n",
    "    for i in range(1, len(texts)):\n",
    "        current = texts[i]\n",
    "        if not current:\n",
    "            continue\n",
    "            \n",
    "        # ‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡πâ‡∏≤‡∏¢ merged ‡∏Å‡∏±‡∏ö‡∏ï‡πâ‡∏ô current\n",
    "        best_overlap = 0\n",
    "        for j in range(1, min(len(merged), len(current)) + 1):\n",
    "            if merged[-j:] == current[:j]:\n",
    "                best_overlap = j\n",
    "        \n",
    "        # ‡∏£‡∏ß‡∏°‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏≠‡∏≠‡∏Å\n",
    "        merged += current[best_overlap:]\n",
    "    \n",
    "    return merged\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def merge_overlapped_text_fuzzy(texts, threshold=85):\n",
    "    if not texts:\n",
    "        return \"\"\n",
    "\n",
    "    merged = texts[0]\n",
    "\n",
    "    for i in range(1, len(texts)):\n",
    "        current = texts[i]\n",
    "        if not current:\n",
    "            continue\n",
    "\n",
    "        best_overlap = 0\n",
    "        max_len = min(len(merged), len(current))\n",
    "\n",
    "        for j in range(1, max_len + 1):\n",
    "            tail = merged[-j:]\n",
    "            head = current[:j]\n",
    "\n",
    "            # ‡πÉ‡∏ä‡πâ fuzzy ratio ‡πÅ‡∏ó‡∏ô exact match\n",
    "            similarity = fuzz.ratio(tail, head)\n",
    "            if similarity >= threshold:  \n",
    "                best_overlap = j\n",
    "\n",
    "        merged += current[best_overlap:]\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9810c4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡∏î‡∏µ‡∏ô‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤',\n",
       " '‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö',\n",
       " '‡πÄ‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡πÄ‡∏à‡πá‡∏î‡∏ô‡∏≤‡∏ó‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',\n",
       " '‡∏ô‡∏≤‡∏ó‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö',\n",
       " '‡πÄ‡∏î‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö‡πÇ‡∏¢‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå',\n",
       " '‡∏¢‡∏≠‡∏û‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå',\n",
       " '',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏à‡∏≠‡∏î‡∏Å‡∏¥‡∏ô‡∏ü‡πâ‡∏≤',\n",
       " '‡∏Å‡πá‡∏à‡∏≠‡∏î‡∏°‡∏µ‡∏ü‡πâ‡∏≤‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏î',\n",
       " '‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏•‡∏≠‡∏î‡πÉ‡∏Ñ‡∏£‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠',\n",
       " '‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Æ‡∏≠‡∏•‡∏•‡∏µ',\n",
       " '‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢',\n",
       " '‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ',\n",
       " '‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°',\n",
       " '‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏µ']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "97f83fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡∏î‡∏µ‡∏ô‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤',\n",
       " '‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡πÄ‡∏à‡πá‡∏î‡∏ô‡∏≤‡∏ó‡∏µ',\n",
       " '‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö',\n",
       " '‡∏¢‡∏≠‡∏û‡∏µ‡πà‡πÄ‡∏ï‡∏≠‡∏£‡πå',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏à‡∏≠‡∏î‡∏Å‡∏¥‡∏ô‡∏ü‡πâ‡∏≤',\n",
       " '‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏î‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏¢‡∏π‡πà',\n",
       " '‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Æ‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡∏î‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢',\n",
       " '‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°',\n",
       " '‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏µ']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7aab92fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡∏î‡∏µ‡∏ô‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤',\n",
       " '‡πÄ‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡πÄ‡∏à‡πá‡∏î‡∏ô‡∏≤‡∏ó‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',\n",
       " '‡πÄ‡∏î‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö‡πÇ‡∏¢‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå',\n",
       " '',\n",
       " '‡∏Å‡πá‡∏à‡∏≠‡∏î‡∏°‡∏µ‡∏ü‡πâ‡∏≤‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏î',\n",
       " '‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Æ‡∏≠‡∏•‡∏•‡∏µ',\n",
       " '‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ',\n",
       " '‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏µ']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19a043ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output: ‡∏î‡∏µ‡∏ô‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡πÄ‡∏à‡πá‡∏î‡∏ô‡∏≤‡∏ó‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö‡πÇ‡∏¢‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏à‡∏±‡∏î‡∏´‡∏°‡∏µ‡∏ü‡πâ‡∏≤‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏•‡∏≠‡∏î‡πÉ‡∏Ñ‡∏£‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Æ‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡∏î‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡∏£‡πâ‡∏≠‡∏á‡∏ó‡∏µ\n",
      "\n",
      "output: ‡∏î‡∏µ‡∏ô‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡πâ‡∏≤‡πÇ‡∏°‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡πÄ‡∏à‡πá‡∏î‡∏ô‡∏≤‡∏ó‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏à‡∏µ‡πä‡∏¢‡∏ö‡πÇ‡∏¢‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏à‡∏±‡∏î‡∏´‡∏°‡∏µ‡∏ü‡πâ‡∏≤‡∏ó‡πç‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡∏õ‡∏•‡∏≠‡∏î‡πÉ‡∏Ñ‡∏£‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡∏î‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡∏£‡πâ‡∏≠‡∏á‡∏ó‡∏µ\n"
     ]
    }
   ],
   "source": [
    "# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "final_text = merge_overlapped_text(texts)\n",
    "print(f\"\\noutput: {final_text}\")\n",
    "\n",
    "final_text = merge_overlapped_text_fuzzy(texts=texts, threshold=85)\n",
    "print(f\"\\noutput: {final_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49733c8",
   "metadata": {},
   "source": [
    "‡πÄ‡∏ó‡∏™‡∏ß‡πà‡∏≤ chunk ‡∏Å‡∏µ‡πà‡∏ß‡∏¥ overlap ‡∏Å‡∏µ‡πà‡∏ß‡∏¥‡∏≠‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏≥ realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2720d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "# def tokenize(text):\n",
    "#     return word_tokenize(text)\n",
    "\n",
    "\n",
    "# def align_sequences(seq1, seq2):\n",
    "#     n, m = len(seq1), len(seq2)\n",
    "\n",
    "#     dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "#     bt = [[None] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "#     for i in range(1, n + 1):\n",
    "#         dp[i][0] = i\n",
    "#         bt[i][0] = (i - 1, 0)\n",
    "#     for j in range(1, m + 1):\n",
    "#         dp[0][j] = j\n",
    "#         bt[0][j] = (0, j - 1)\n",
    "\n",
    "#     for i in range(1, n + 1):\n",
    "#         for j in range(1, m + 1):\n",
    "#             cost = 0 if seq1[i-1] == seq2[j-1] else 1\n",
    "\n",
    "#             choices = [\n",
    "#                 (dp[i-1][j] + 1, (i-1, j)),\n",
    "#                 (dp[i][j-1] + 1, (i, j-1)),\n",
    "#                 (dp[i-1][j-1] + cost, (i-1, j-1))\n",
    "#             ]\n",
    "#             dp[i][j], bt[i][j] = min(choices, key=lambda x: x[0])\n",
    "\n",
    "#     aligned = []\n",
    "#     i, j = n, m\n",
    "#     while i > 0 or j > 0:\n",
    "#         pi, pj = bt[i][j]\n",
    "#         if pi == i - 1 and pj == j - 1:\n",
    "#             aligned.append((i-1, j-1))\n",
    "#         elif pi == i - 1 and pj == j:\n",
    "#             aligned.append((i-1, None))\n",
    "#         else:\n",
    "#             aligned.append((None, j-1))\n",
    "#         i, j = pi, pj\n",
    "\n",
    "#     aligned.reverse()\n",
    "#     return aligned\n",
    "\n",
    "\n",
    "# def merge_two(prev_text, new_text):\n",
    "#     seq1 = tokenize(prev_text)\n",
    "#     seq2 = tokenize(new_text)\n",
    "\n",
    "#     print(seq1)\n",
    "#     print(seq2)\n",
    "#     alignment = align_sequences(seq1, seq2)\n",
    "#     print(alignment)\n",
    "#     cut_pos = 0\n",
    "#     for (i, j) in alignment:\n",
    "#         if i is None or j is None:\n",
    "#             cut_pos = j if j is not None else cut_pos\n",
    "#             break\n",
    "#         if seq1[i] != seq2[j]:\n",
    "#             cut_pos = j\n",
    "#             break\n",
    "#         cut_pos = j + 1\n",
    "\n",
    "#     return prev_text + new_text[len(''.join(seq2[:cut_pos])):]\n",
    "\n",
    "\n",
    "# def merge_overlapped_text_aligner(texts):\n",
    "#     if not texts:\n",
    "#         return \"\"\n",
    "\n",
    "#     merged = texts[0]\n",
    "#     for i in range(1, len(texts)):\n",
    "#         merged = merge_two(merged, texts[i])\n",
    "#         print(merged)\n",
    "\n",
    "#     return merged\n",
    "\n",
    "# def merge_two(prev_text, new_text):\n",
    "#     seq1 = tokenize(prev_text)\n",
    "#     seq2 = tokenize(new_text)\n",
    "#     print(seq1)\n",
    "#     print(seq2)\n",
    "#     alignment = align_sequences(seq1, seq2)\n",
    "\n",
    "#     # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á token ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô seq2\n",
    "#     # ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: new tokens ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà i == None\n",
    "#     new_tokens = []\n",
    "#     for (i, j) in alignment:\n",
    "#         if i is None and j is not None:\n",
    "#             new_tokens.append(seq2[j])\n",
    "\n",
    "#     # merge = seq1 + new_tokens\n",
    "#     merged_tokens = seq1 + new_tokens\n",
    "#     return ''.join(merged_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "498a3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_overlapped_text_aligner(texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thai-voice-transcription",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
